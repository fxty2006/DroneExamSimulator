import streamlit as st
import pandas as pd
import glob
import os
import json
import time
import check_db
import export_review
import import_review

def render(locked):
    st.header("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ç®¡ç†")
    
    base = os.path.dirname(os.path.abspath(__file__))
    data_dir = os.path.join(base, "data")
    report_path = os.path.join(data_dir, "csv_review", "reported.csv")
    
    # ------------------------------------------------
    # 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼å ±å‘Šã‚»ã‚¯ã‚·ãƒ§ãƒ³ (å†…å®¹ã®ä¸å‚™)
    # ------------------------------------------------
    st.subheader("ğŸ“¢ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å ±å‘Š (å†…å®¹ã®ä¸å‚™)")
    st.caption("æ¨¡æ“¬è©¦é¨“ï¼ˆç·´ç¿’ãƒ¢ãƒ¼ãƒ‰ï¼‰ä¸­ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰å ±å‘Šã•ã‚ŒãŸå•é¡Œã®ä¸€è¦§ã§ã™ã€‚CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚’è¡Œã£ã¦å†…å®¹ã‚’ä¿®æ­£ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ‰ç„¡ã‚’ç¢ºèª
    if os.path.exists(report_path):
        # èª­ã¿è¾¼ã¿å‡¦ç†ã¨è¡¨ç¤º
        try:
            df_report = pd.read_csv(report_path)
            if not df_report.empty:
                st.error(f"âš ï¸ **{len(df_report)} ä»¶ã®å ±å‘ŠãŒã‚ã‚Šã¾ã™**")
                st.dataframe(df_report, use_container_width=True)
                
                # å±¥æ­´ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
                if st.button("ğŸ—‘ï¸ å ±å‘Šå±¥æ­´ã‚’å…¨ã¦æ¶ˆå»", type="secondary"):
                    os.remove(report_path)
                    st.success("å±¥æ­´ã‚’æ¶ˆå»ã—ã¾ã—ãŸã€‚ç”»é¢ã‚’æ›´æ–°ã—ã¾ã™...")
                    time.sleep(1)
                    st.rerun()
            else:
                st.info("âœ… ç¾åœ¨ã€å ±å‘Šã•ã‚ŒãŸå•é¡Œã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        except Exception as e:
            # st.rerun() ã«ã‚ˆã‚‹ä¸­æ–­ã¯ã“ã“ã§ã‚­ãƒ£ãƒƒãƒã—ãªã„ã‚ˆã†ã«æ³¨æ„ãŒå¿…è¦ã ãŒ
            # Streamlitã®ä»•æ§˜ä¸Šã€rerunã¯ä¾‹å¤–ã‚’æŠ•ã’ã‚‹ãŸã‚ã€æ„å›³ã—ãªã„ã‚¨ãƒ©ãƒ¼è¡¨ç¤ºã‚’é˜²ã
            if "scriptrunner.script_runner.StopException" not in str(type(e)):
                st.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    else:
        st.info("âœ… ç¾åœ¨ã€å ±å‘Šã•ã‚ŒãŸå•é¡Œã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

    st.divider()

    # ------------------------------------------------
    # 2. ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã‚¨ãƒ©ãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³ (ã‚·ã‚¹ãƒ†ãƒ çš„ãªä¸å‚™)
    # ------------------------------------------------
    st.subheader("âš ï¸ ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ (ã‚·ã‚¹ãƒ†ãƒ ã®ä¸å‚™)")
    st.caption("ãƒ•ã‚¡ã‚¤ãƒ«ã®ç ´æã‚„å¿…é ˆé …ç›®ã®æ¬ è½ãªã©ã€ã‚·ã‚¹ãƒ†ãƒ çš„ãªä¸å‚™ã‚’è¨ºæ–­ã—ãŸçµæœã§ã™ã€‚")

    # ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã®é›†è¨ˆ
    files = glob.glob(os.path.join(data_dir, "db_*.json"))
    files = [f for f in files if "db_status.json" not in f]
    total_q_count = 0
    for f in files:
        try:
            with open(f,'r',encoding='utf-8') as fp: total_q_count += len(json.load(fp))
        except: pass
    
    m1, m2, m3 = st.columns(3)
    m1.metric("ğŸ“ ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°", f"{len(files)} ãƒ•ã‚¡ã‚¤ãƒ«")
    m2.metric("ğŸ“ ç·å•é¡Œæ•°", f"{total_q_count} å•")

    msg = st.session_state.maintenance_msg
    if msg:
        if msg['type'] == 'success': st.success(msg['content'])
        elif msg['type'] == 'warning': st.warning(msg['content'])

    if st.session_state.db_errors:
        st.error(f"âš ï¸ **{len(st.session_state.db_errors)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ä¸å‚™ãŒã‚ã‚Šã¾ã™**")
        df_err = pd.DataFrame(st.session_state.db_errors)
        st.dataframe(df_err, use_container_width=True)
    else:
        st.success("âœ… ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«å•é¡Œã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        
    st.markdown("---")
    
    # ------------------------------------------------
    # 3. ãƒ„ãƒ¼ãƒ«ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    # ------------------------------------------------
    c1, c2, c3 = st.columns(3)
    with c1:
        st.subheader("ğŸ› ï¸ è¨ºæ–­ãƒ»ä¿®å¾©")
        st.caption("ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚")
        if st.button("è¨ºæ–­ã‚’å®Ÿè¡Œ (Check)", disabled=locked):
            logs, count, errors = check_db.check_and_clean(silent=True)
            st.session_state.db_errors = errors
            if errors:
                txt = f"âš ï¸ **è¨ºæ–­å®Œäº†**: {len(errors)}ä»¶ã®ä¸å‚™ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚"
                st.session_state.maintenance_msg = {'type': 'warning', 'content': txt}
            else:
                txt = f"âœ… **è¨ºæ–­å®Œäº†**: ç•°å¸¸ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\n(â€» {count}ä»¶ã®è‡ªå‹•ä¿®å¾©ã‚’è¡Œã„ã¾ã—ãŸ)"
                st.session_state.maintenance_msg = {'type': 'success', 'content': txt}
            st.rerun()

    with c2:
        st.subheader("ğŸ“¤ CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
        st.caption("ç·¨é›†ç”¨ã«å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚")
        if st.button("å‡ºåŠ›ã‚’å®Ÿè¡Œ (Export)", disabled=locked):
            fc, qc, path = export_review.run_export()
            if fc > 0:
                txt = f"âœ… **å®Œäº†**: {fc}ãƒ•ã‚¡ã‚¤ãƒ« ({qc}å•)\nä¿å­˜å…ˆ: {path}"
                st.session_state.maintenance_msg = {'type': 'success', 'content': txt}
            else:
                st.session_state.maintenance_msg = {'type': 'warning', 'content': "âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"}
            st.rerun()

    with c3:
        st.subheader("ğŸ“¥ CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
        st.caption("ç·¨é›†å¾Œã®CSVã‚’å–ã‚Šè¾¼ã¿ã¾ã™ã€‚")
        if st.button("å–è¾¼ã‚’å®Ÿè¡Œ (Import)", disabled=locked):
            fc, uc = import_review.run_import()
            if fc > 0:
                logs, count, errors = check_db.check_and_clean(silent=True)
                st.session_state.db_errors = errors
                if not errors:
                    txt = f"âœ… **å®Œäº†**: {uc}ä»¶æ›´æ–°ã€‚ä¸å‚™ã¯è§£æ¶ˆã•ã‚Œã¾ã—ãŸï¼"
                    st.session_state.maintenance_msg = {'type': 'success', 'content': txt}
                else:
                    txt = f"âš ï¸ **å®Œäº†**: {uc}ä»¶æ›´æ–°ã—ã¾ã—ãŸãŒã€{len(errors)}ä»¶ã®ä¸å‚™ãŒã‚ã‚Šã¾ã™ã€‚"
                    st.session_state.maintenance_msg = {'type': 'warning', 'content': txt}
            else:
                st.session_state.maintenance_msg = {'type': 'warning', 'content': "âš ï¸ CSVãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"}
            st.rerun()